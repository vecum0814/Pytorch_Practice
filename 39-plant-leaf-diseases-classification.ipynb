{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 데이터 분할을 위한 하위 폴더 생성","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\n\n\noriginal_datset_dir = '../input/plant-leaf-diseases-without-aug/Plant_leave_diseases_dataset_with_augmentation' # 원본 데이터셋의 경로를 지정.\nclasses_list = os.listdir(original_datset_dir) # 하위에 있는 모든 폴더의 목록을 클래스 이름으로 가져온다.\n\nbase_dir = './splitted'\n\nos.mkdir(base_dir) # 용도별로 나눌 폴더를 생성.\n\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\nval_dir = os.path.join(base_dir, 'val')\nos.mkdir(val_dir)\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)\n\nfor cls in classes_list:\n    os.mkdir(os.path.join(train_dir, cls))\n    os.mkdir(os.path.join(val_dir, cls))\n    os.mkdir(os.path.join(test_dir, cls))\n    \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-22T16:21:41.752221Z","iopub.execute_input":"2022-07-22T16:21:41.752945Z","iopub.status.idle":"2022-07-22T16:21:41.792049Z","shell.execute_reply.started":"2022-07-22T16:21:41.752848Z","shell.execute_reply":"2022-07-22T16:21:41.791152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 분할과 클래스별 데이터 수 확인","metadata":{}},{"cell_type":"code","source":"import math\n\nfor cls in classes_list:\n    path = os.path.join(original_datset_dir, cls)\n    fnames = os.listdir(path) # 각 클래스마다 존재하는 모든 이미지 파일의 목록을 fname에 저장한다.\n    \n    train_size = math.floor(len(fnames) * 0.6)\n    val_size = math.floor(len(fnames) * 0.2)\n    test_size = math.floor(len(fnames) * 0.2)    \n    \n    train_fnames = fnames[:train_size]\n    print('Train size(',cls,'): ', len(train_fnames))\n    for fname in train_fnames:\n        src = os.path.join(path, fname)\n        dst = os.path.join(os.path.join(train_dir, cls), fname)\n        shutil.copyfile(src, dst) # src의 경로에 해당하는 파일을 dst의 경로에 저장한다. \n        \n    val_fnames = fnames[train_size : (val_size + train_size)]\n    #print('Validation size(',cls,'): ', len(val_fnames))\n    for fname in val_fnames:\n        src = os.path.join(path, fname)\n        dst = os.path.join(os.path.join(val_dir, cls), fname)\n        shutil.copyfile(src, dst) # src의 경로에 해당하는 파일을 dst의 경로에 저장한다. \n        \n\n    test_fnames = fnames[(val_size + train_size) : (val_size + train_size + test_size)]\n    #print('Test size(',cls,'): ', len(test_fnames))\n    for fname in test_fnames:\n        src = os.path.join(path, fname)\n        dst = os.path.join(os.path.join(test_dir, cls), fname)\n        shutil.copyfile(src, dst) # src의 경로에 해당하는 파일을 dst의 경로에 저장한다. \n        ","metadata":{"execution":{"iopub.status.busy":"2022-07-22T16:23:47.472942Z","iopub.execute_input":"2022-07-22T16:23:47.473323Z","iopub.status.idle":"2022-07-22T16:27:06.036540Z","shell.execute_reply.started":"2022-07-22T16:23:47.473282Z","shell.execute_reply":"2022-07-22T16:27:06.035587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 베이스라인 모델 학습을 위한 준비","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\nimport torchvision\nimport numpy as np\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#print(device)\nbatch_size = 64\nepoch = 30\n\n# Weighted Random Sampling을 위한 함수 정의\n\ndef make_weights_for_balanced_classes(img, nclasses):\n\n    labels = []\n    for i in range(len(img)):\n        labels.append(img[i][1])\n\n    label_array = np.array(labels)\n    total = len(labels)\n\n    count_list = []\n    for cls in range(nclasses):\n        count = len(np.where(label_array == cls)[0])\n        count_list.append(total/count)\n\n    weights = []\n    for label in label_array:\n        weights.append(count_list[label])\n\n    return weights\n\n\n\n\ntransf = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n\ntrain_dataset = ImageFolder(root = './splitted/train', transform = transf)\nval_dataset = ImageFolder(root = './splitted/val', transform = transf)\n\nweights_train = make_weights_for_balanced_classes(train_dataset.imgs, len(train_dataset.classes)) # 가중치 계산\nweights_train = torch.DoubleTensor(weights_train) # 텐서 변환\nsampler_train = torch.utils.data.sampler.WeightedRandomSampler(weights_train, len(weights_train)) # 샘플링 방법 정의\n\nweights_val = make_weights_for_balanced_classes(val_dataset.imgs, len(val_dataset.classes)) # 가중치 계산\nweights_val = torch.DoubleTensor(weights_val) # 텐서 변환\nsampler_val = torch.utils.data.sampler.WeightedRandomSampler(weights_val, len(weights_val)) # 샘플링 방법 정의\n\ntrain_loader = DataLoader(train_dataset, batch_size = batch_size, sampler = sampler_train) # 데이터 로더 정의\nval_loader = DataLoader(val_dataset, batch_size = batch_size, sampler = sampler_val) # 데이터 로더 정의\n\n#train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True) # 데이터 로더 정의\n#val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n\nprint(len(train_dataset.classes))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-22T16:31:23.700101Z","iopub.execute_input":"2022-07-22T16:31:23.700706Z","iopub.status.idle":"2022-07-22T16:31:26.032495Z","shell.execute_reply.started":"2022-07-22T16:31:23.700673Z","shell.execute_reply":"2022-07-22T16:31:26.030594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 베이스라인 모델 설계","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 32, kernel_size = 3, padding = 1)\n        self.maxpool = nn.MaxPool2d(2, 2)\n        self.relu = nn.ReLU(inplace = True)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size = 3, padding = 1)\n        self.conv3 = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\n        \n        self.bn1 = nn.BatchNorm2d(32)\n        self.bn2 = nn.BatchNorm2d(64)\n        \n        \n        self.fc1 = nn.Linear(4096, 512)\n        self.fc2 = nn.Linear(512, 39)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = F.dropout(x, p = 0.25, training = self.training)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = F.dropout(x, p = 0.25, training = self.training)\n        \n        x = self.conv3(x)\n        #x = self.bn2(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = F.dropout(x, p = 0.25, training = self.training)\n        \n        x = x.view(-1, 4096)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = F.dropout(x, p = 0.5, training = self.training) \n        x = self.fc2(x) \n        \n        return F.log_softmax(x, dim = 1)\n    \nmodel = Model().to(device)\noptimizer = optim.Adam(model.parameters(), lr = 1e-3)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:04:51.656965Z","iopub.execute_input":"2022-07-22T17:04:51.657433Z","iopub.status.idle":"2022-07-22T17:04:51.874600Z","shell.execute_reply.started":"2022-07-22T17:04:51.657394Z","shell.execute_reply":"2022-07-22T17:04:51.873497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 모델 학습과 평가를 위한 함수","metadata":{}},{"cell_type":"code","source":"def train(model, train_loader, optimizer):\n    model.train() # 입력 받는 모델을 학습 모드로 설정.\n    \n    for (x, y) in train_loader:\n        x = x.to(device)\n        y = y.to(device)\n   # for batch_idx, (x, y) in enumerate(train_loader):  \n    #    x, y = x.to(device), y.to(device)\n            \n        optimizer.zero_grad() # 이전 batch의 gradient값이 옵티마이저에 저장되어 있으므로 초기화 시켜준다.\n        y_pred = model(x)\n        loss = F.cross_entropy(y_pred, y)\n        loss.backward() # 계산한 loss값을 바탕으로 역전파를 통해 계산한 gradient 값을 각 parameter에 할당한다.\n        optimizer.step() # 각 parameter에 할당된 gradient 값을 이용해 모델의 parameter를 업데이트 한다.\n        \ndef evaluate(model, test_loader):\n    epoch_loss = 0\n    epoch_acc = 0\n    correct = 0\n    \n    model.eval() # 입력 받는 모델을 평가 모드로 설정. \n    with torch.no_grad(): # 해당 메서드를 이용하여 해당 부분을 실행하는 동안 모델의 Parameter 업데이트를 중단한다. \n        for (x, y) in test_loader:\n            x = x.to(device)\n            y = y.to(device)\n            y_pred = model(x)\n            \n            epoch_loss += F.cross_entropy(y_pred, y, reduction = 'sum').item()\n            pred = y_pred.max(1, keepdim = True)[1] # 모델에 입력된 test 데이터가 33개의 클래스에 속할 각각의 확률값을 반환 -> 이 중 가장 높은 값을 가진 인덱스를 예측값으로 pred에 저장.\n            correct += pred.eq(y.view_as(pred)).sum().item() # y.view_as(pred)를 통해 y Tensor의 구조를 pred Tensor의 모양대로 재정렬 -> 일치하는 갯수만큼 반환\n            \n    epoch_loss /= len(test_loader.dataset)\n    epoch_acc = 100. * correct / len(test_loader.dataset)\n    return epoch_loss, epoch_acc\n        \n        \n        \n        \n","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:04:55.516597Z","iopub.execute_input":"2022-07-22T17:04:55.517199Z","iopub.status.idle":"2022-07-22T17:04:55.528523Z","shell.execute_reply.started":"2022-07-22T17:04:55.517159Z","shell.execute_reply":"2022-07-22T17:04:55.526457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 모델 학습 실행하기","metadata":{}},{"cell_type":"code","source":"import time\nimport copy\n\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\ndef train_baseline(model, train_loader, val_loader, optimizer, num_epochs = 30):\n    best_acc = 0.0\n    #print('1')\n    best_model_weights = copy.deepcopy(model.state_dict())\n    \n    for epoch in range(1, num_epochs + 1):\n       # print('2')\n        since = time.time()\n        train(model, train_loader, optimizer)\n        train_loss, train_acc = evaluate(model, train_loader)\n        val_loss, val_acc = evaluate(model, val_loader)\n        \n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_model_weights = copy.deepcopy(model.state_dict())\n            \n        time_elapsed = time.time() - since\n        print('---------- epoch {} ----------'.format(epoch))\n        print('Train Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))\n        print('Validation Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n        \n    model.load_state_dict(best_model_weights)\n    return model\n\nbase_model = train_baseline(model, train_loader, val_loader, optimizer, epoch)\ntorch.save(base_model, 'base_model.pt')","metadata":{"execution":{"iopub.status.busy":"2022-07-22T17:04:58.565856Z","iopub.execute_input":"2022-07-22T17:04:58.566542Z","iopub.status.idle":"2022-07-22T18:27:44.395246Z","shell.execute_reply.started":"2022-07-22T17:04:58.566499Z","shell.execute_reply":"2022-07-22T18:27:44.393309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning을 위한 준비","metadata":{}},{"cell_type":"code","source":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((64, 64)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomCrop(52),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((64, 64)),\n        transforms.RandomCrop(52),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ])\n}\n\ndata_dir = './splitted'\nimage_datasets = {x: ImageFolder(root = os.path.join(data_dir, x), transform = data_transforms[x])\n                     for x in {'train', 'val'}}\ndataloaders = {x: DataLoader(image_datasets[x], batch_size = batch_size, shuffle = True) for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes","metadata":{"execution":{"iopub.status.busy":"2022-07-22T18:30:04.167608Z","iopub.execute_input":"2022-07-22T18:30:04.168022Z","iopub.status.idle":"2022-07-22T18:30:04.510767Z","shell.execute_reply.started":"2022-07-22T18:30:04.167987Z","shell.execute_reply":"2022-07-22T18:30:04.509632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-Trained Model 불러오기","metadata":{}},{"cell_type":"code","source":"from torchvision import models\nfrom torch.optim import lr_scheduler\n\n\nresnet = models.resnet50(pretrained = True)\nn_filters = resnet.fc.in_features # 불러온 ResNet50의 마지막 Layer의 입력 채널의 수.\nresnet.fc = nn.Linear(n_filters, 39)# 불러온 모델의 마지막 FC 레이어를 새로운 레이어로 교체\nresnet = resnet.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer_ft = optim.Adam(filter(lambda p : p.requires_grad, resnet.parameters()), lr = 1e-3) # requires_grad = True로 설정된 레이어의 parameter만 업데이트.\n\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size = 7, gamma = 0.1)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-22T18:31:01.476791Z","iopub.execute_input":"2022-07-22T18:31:01.477489Z","iopub.status.idle":"2022-07-22T18:31:02.224241Z","shell.execute_reply.started":"2022-07-22T18:31:01.477443Z","shell.execute_reply":"2022-07-22T18:31:02.223293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-Trained 모델의 일부 Layer Freeze 시키기","metadata":{}},{"cell_type":"code","source":"count = 0\nfor child in resnet.children(): # .children() -> 모델의 자식 모듈을 iterable한 객체로 반환, 즉 resnet 모델의 모든 레이어 정보를 담고 있다.\n    count += 1\n    if count < 6:\n        for param in child.parameters(): # ResNet50에 존재하는 10개의 레이어 중에서 1-5번 레이어의 parameter를 freeze.\n            param.rquires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-07-22T18:31:04.731410Z","iopub.execute_input":"2022-07-22T18:31:04.731784Z","iopub.status.idle":"2022-07-22T18:31:04.737921Z","shell.execute_reply.started":"2022-07-22T18:31:04.731757Z","shell.execute_reply":"2022-07-22T18:31:04.736752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning 모델 학습과 검증을 위한 함수","metadata":{}},{"cell_type":"code","source":"def train_resnet(model, optimizer, criterion, scheduler, num_epochs = 15):\n    best_acc = 0.0\n    best_model_weights = copy.deepcopy(model.state_dict())\n    \n    for epoch in range(1, num_epochs + 1):\n        print('---------- epoch {} ----------'.format(epoch))\n        since = time.time()\n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n                \n            epoch_loss = 0.0\n            epoch_corrects = 0\n            \n            for (x, y) in dataloaders[phase]:\n                x = x.to(device)\n                y = y.to(device)\n                \n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'): # set_grad_enabled() 메서드를 이용하여 PHASE가 TRAIN일 경우에만 모델의 Gradient가 업데이트 되도록 설정.\n                    y_pred = model(x)\n                    _, predicted = torch.max(y_pred, 1) \n                    loss = criterion(y_pred, y)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                        \n                epoch_loss += loss.item() * x.size(0)\n                epoch_corrects += torch.sum(predicted == y.data)\n            \n            if phase == 'train':\n                scheduler.step() # 설정된 7번의 Epoch마다 학습률을 다르게 조정하는 것을 반영. \n                lr = [x['lr'] for x in optimizer_ft.param_groups] # 학습률이 조정되고 있는것을 확인하기 위해 각 Epoch의 lr parameter를 불러온다.\n                print('learning_rate: ', lr)\n                \n                \n            epoch_loss /= dataset_sizes[phase]\n            epoch_acc = epoch_corrects.double() / dataset_sizes[phase]\n            \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_weights = copy.deepcopy(model.state_dict())\n                \n        time_elapsed = time.time() - since\n        print('Completed in {:0f}m {:0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    \n    print('Best validation Acc: {:4f}'.format(best_acc))\n    \n    model.load_state_dict(best_model_weights)\n    \n    return model\n                    \n                    \n                    \n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-22T18:52:01.576154Z","iopub.execute_input":"2022-07-22T18:52:01.576684Z","iopub.status.idle":"2022-07-22T18:52:01.591359Z","shell.execute_reply.started":"2022-07-22T18:52:01.576651Z","shell.execute_reply":"2022-07-22T18:52:01.590374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 모델 학습 실행하기","metadata":{}},{"cell_type":"code","source":"model_resnet50 = train_resnet(resnet, optimizer_ft, criterion, exp_lr_scheduler, num_epochs = 15)\ntorch.save(model_resnet50, 'resnet50.pt') \n","metadata":{"execution":{"iopub.status.busy":"2022-07-22T18:52:03.643084Z","iopub.execute_input":"2022-07-22T18:52:03.643690Z","iopub.status.idle":"2022-07-22T19:27:17.251068Z","shell.execute_reply.started":"2022-07-22T18:52:03.643655Z","shell.execute_reply":"2022-07-22T19:27:17.249984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 베이스라인 모델 평가를 위한 전처리 과정","metadata":{}},{"cell_type":"code","source":"test_base = ImageFolder(root = './splitted/test', transform = transf)\ntest_loader_base = DataLoader(test_base, batch_size = batch_size, shuffle = True)\n                                ","metadata":{"execution":{"iopub.status.busy":"2022-07-22T19:46:23.453989Z","iopub.execute_input":"2022-07-22T19:46:23.454597Z","iopub.status.idle":"2022-07-22T19:46:23.518369Z","shell.execute_reply.started":"2022-07-22T19:46:23.454562Z","shell.execute_reply":"2022-07-22T19:46:23.517433Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning 모델 평가를 위한 전처리 과정","metadata":{}},{"cell_type":"code","source":"transf_resNet = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.RandomCrop(52),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        [0.485, 0.456, 0.406],\n        [0.229, 0.224, 0.225])\n])\n\ntest_resNet = ImageFolder(root = './splitted/test', transform = transf_resNet)\ntest_loader_resNet = DataLoader(test_resNet, batch_size = batch_size, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T19:46:25.398973Z","iopub.execute_input":"2022-07-22T19:46:25.399320Z","iopub.status.idle":"2022-07-22T19:46:25.468004Z","shell.execute_reply.started":"2022-07-22T19:46:25.399290Z","shell.execute_reply":"2022-07-22T19:46:25.467026Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"# 베이스라인 모델 성능 평가","metadata":{}},{"cell_type":"code","source":"baseline = torch.load('base_model.pt')\nbaseline.eval()\ntest_loss, test_accuracy = evaluate(baseline, test_loader_base)\n\nprint('Baseline test Acc: ', test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T19:46:27.874086Z","iopub.execute_input":"2022-07-22T19:46:27.875197Z","iopub.status.idle":"2022-07-22T19:46:52.520036Z","shell.execute_reply.started":"2022-07-22T19:46:27.875126Z","shell.execute_reply":"2022-07-22T19:46:52.518780Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning 모델 성능 평가","metadata":{}},{"cell_type":"code","source":"resnet50 = torch.load('resnet50.pt')\nresnet50.eval()\ntest_loss, test_accuracy = evaluate(resnet50, test_loader_resNet)\n\nprint('ResNet test Acc: ', test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T19:47:22.954103Z","iopub.execute_input":"2022-07-22T19:47:22.954783Z","iopub.status.idle":"2022-07-22T19:47:52.769955Z","shell.execute_reply.started":"2022-07-22T19:47:22.954746Z","shell.execute_reply":"2022-07-22T19:47:52.768834Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}